<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>Large Scale Image Annotation: Learning to Rank with Joint Word-Image Embeddings</title>
        <meta name="viewport" content="width=device-width,initial-scale=1.0">
        <link rel="stylesheet" href="/static/css/main.min.css" type="text/css" media="all">
        <!--[if lte IE 8]>
            <link
                rel="stylesheet"
                href="/static/css/ie-fixes.css"
                type="text/css"
                media="all"
            />
            <script src="/static/js/html5shiv.js"></script>
        <![endif]-->

        <meta http-equiv="last-modified" content="Thu, 10 Mar 2011 16:16:25 GMT">
        <link rel="alternate" type="application/atom+xml" title="All Posts (Atom)" href="/feeds/all.atom">
        <link rel="alternate" type="application/rss+xml" title="All Posts (RSS)" href="/feeds/all.rss">
        <link rel="icon" type="image/jpeg" sizes="287x287" href="/static/img/favicon-287x287.jpg">
        <link rel="icon" type="image/jpeg" sizes="128x128" href="/static/img/favicon-128x128.jpg">
    </head>
    <body class="blog post_detail" itemscope itemtype="http://schema.org/BlogPosting">
        <nav id="site-nav">
            <header id="about">
                <h1><a href="/about/">Chris Adams</a></h1>
                <h2>Programmer, cyclist, photographer</h2>
            </header>
            <ul class="links">
                <li>
                    <a href="/">Home</a>
                </li>
                <li>
                    <a href="/about/">About</a>
                </li>
                <li>
                    <a href="/feeds/all.atom" title="Site Feed">Site Feed</a>
                </li>
            </ul>
            <ul class="social-networks">
                <li>
                    <a rel="me" href="https://code4lib.social/@acdha">Mastodon</a>
                </li>
                <li>
                    <a href="https://github.com/acdha" rel="me">Github</a>
                </li>
                <li>
                    <a href="https://bitbucket.org/acdha" rel="me">Bitbucket</a>
                </li>
                <li>
                    <a href="https://pinboard.in/u:acdha/" rel="me">Pinboard</a>
                </li>
                <li>
                    <a href="https://www.flickr.com/photos/acdha" rel="me">Flickr</a>
                </li>
                <li>
                    <a href="https://www.linkedin.com/in/acdha" rel="me">LinkedIn</a>
                </li>
            </ul>
            <div id="site-search"></div>
        </nav>
        <section id="main">
            <article class="post">
                <header>
                    <meta itemprop="dateCreated" content="2011-03-10T11:00:00-04:00">
                    <meta itemprop="dateModified" content="2011-03-10T11:00:00-04:00">
                    <time class="date" itemprop="datePublished" datetime="2011-03-10T15:00:00+00:00">Mar 10</time>
                    <h2 class="" itemprop="title">Large Scale Image Annotation: Learning to Rank with Joint Word-Image Embeddings</h2>
                </header>

                <div class="body" itemprop="articleBody"><div class="googlereader description" data-google-id="tag:google.com,2005:reader/item/c525ef713a2c1f3c">
                        <blockquote>
                            <span>Posted by Jason Weston and Samy Bengio, Research Team</span><br>
                            <br>
                            In our <a href="http://www.google.com/research/pubs/pub35780.html">paper</a>, we introduce a generic framework to find a joint representation of images and their labels, which can then be used for various tasks, including image ranking and image annotation.<br>
                            <br>
                            We focus on the task of automatic assignment of annotations (text labels) to images given only the pixel representation of the image (i.e., with no known metadata). This is achieved by a learning algorithm, that is, where the computer learns to predict annotations for new images given annotated training images. Such training datasets are becoming larger and larger, with tens of millions of images and tens of thousands of possible annotations. In this paper, we propose a strongly performing method that scales to such datasets by simultaneously learning to optimize precision at the top of the ranked list of annotations for a given image and learning a low-dimensional joint embedding vector space for both images and annotations. Our system learns an interpretable model, where annotations with alternate wordings ("president obama" or "barack"), different languages ("tour eiï¬€el" or "eiffel tower"), or similar concepts (such as "toad" or "frog") are close in the embedding space. Hence, even when our model does not predict the exact annotation given by a human labeler, it often predicts similar annotations.<br>
                            <br>
                            Our system is trained on ~10 million images with ~100,000 possible annotation types and it annotates a single new image in ~0.17 seconds (not including feature processing) and consumes only 82MB of memory. Our method both outperforms all the methods we tested against and in comparison to them is faster and consumes less memory, making it possible to house such a system on a laptop or mobile device.
                            <div>
                                <img width="1" height="1" src="https://blogger.googleusercontent.com/tracker/21224994-7878514956378010370?l=googleresearch.blogspot.com" alt="">
                            </div>
                            <div>
                                <a href="http://feeds.feedburner.com/~ff/blogspot/gJZg?a=w8EKL7dvxiw:D26I5aQVrk4:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/blogspot/gJZg?d=yIl2AUoC8zA" border="0"></a>
                            </div>
                        </blockquote>
                    </div>
                    <p class="bookmark-source">
                        Source: <a href="http://googleresearch.blogspot.com/2011/03/large-scale-image-annotation-learning.html?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+blogspot%2FgJZg+%28Official+Google+Research+Blog%29">http://googleresearch.blogspot.com/2011/03/large-scale-image-annotation-learning.html?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+blogspot%2FgJZg+%28Official+Google+Research+Blog%29</a>
                    </p>
                </div>
            </article>

            <nav id="post-nav">


            </nav>
        </section>

        <footer id="site-footer" class="nocontent">
            <p>
                This site is purely my personal work and does not reflect the
                views of my employer.
            </p>
            <p class="license">
                <a class="icon" rel="license" href="https://creativecommons.org/licenses/by-sa/3.0/deed.en_US"><img alt="Creative Commons License" style="border-width: 0" src="https://i.creativecommons.org/l/by-sa/3.0/88x31.png"></a>
                This work is licensed under a
                <a rel="license" href="https://creativecommons.org/licenses/by-sa/3.0/deed.en_US">Creative Commons Attribution-ShareAlike 3.0 Unported
                    License</a>.
            </p>
        </footer>

        <script async src="/static/js/common.js"></script>
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/prettify/r298/run_prettify.min.js" integrity="sha256-hj+5FRlAuvAFANiefn0PpJYCkV1X4QT9EgiPd+6QnCw=" crossorigin="anonymous"></script>
    </body>
</html>
