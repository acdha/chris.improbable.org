<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>
            Four revolutions
        </title>
        <meta name="viewport" content="width=device-width,initial-scale=1.0">
        <link rel="stylesheet" href="/static/css/main.min.css" type="text/css" media="all"><!--[if lte IE 8]>
            <link rel="stylesheet" href="/static/css/ie-fixes.css" type="text/css" media="all">
            <script src="/static/js/html5shiv.js"></script>
        <![endif]-->
        <meta http-equiv="last-modified" content="Sat, 05 Feb 2011 20:46:13 GMT">
        <link rel="alternate" type="application/atom+xml" title="All Posts (Atom)" href="/feeds/all.atom">
        <link rel="alternate" type="application/rss+xml" title="All Posts (RSS)" href="/feeds/all.rss">
        <link rel="icon" type="image/jpeg" sizes="287x287" href="/static/img/favicon-287x287.jpg">
        <link rel="icon" type="image/jpeg" sizes="128x128" href="/static/img/favicon-128x128.jpg">
        <script type="application/javascript">
var _prum={id:"5166be01e6e53d1007000001"};var PRUM_EPISODES=PRUM_EPISODES||{};PRUM_EPISODES.q=[];PRUM_EPISODES.mark=function(b,a){PRUM_EPISODES.q.push(["mark",b,a||new Date().getTime()])};PRUM_EPISODES.measure=function(b,a,b){PRUM_EPISODES.q.push(["measure",b,a,b||new Date().getTime()])};PRUM_EPISODES.done=function(a){PRUM_EPISODES.q.push(["done",a])};PRUM_EPISODES.mark("firstbyte");(function(){var b=document.getElementsByTagName("script")[0];var a=document.createElement("script");a.type="text/javascript";a.async=true;a.charset="UTF-8";a.src="//rum-static.pingdom.net/prum.min.js";b.parentNode.insertBefore(a,b)})();
        </script>
    </head>
    <body class="blog post_detail" itemscope itemtype="http://schema.org/BlogPosting">
        <nav id="site-nav">
            <header id="about">
                <h1>
                    <a href="/about/">Chris Adams</a>
                </h1>
                <h2>
                    Programmer, cyclist, photographer
                </h2>
            </header>
            <ul class="links">
                <li>
                    <a href="/">Home</a>
                </li>
                <li>
                    <a href="/about/">About</a>
                </li>
                <li>
                    <a href="/feeds/all.atom" title="Site Feed">Site Feed</a>
                </li>
            </ul>
            <ul class="social-networks">
                <li>
                    <a href="https://github.com/acdha" rel="me">Github</a>
                </li>
                <li>
                    <a href="http://bitbucket.org/acdha" rel="me">Bitbucket</a>
                </li>
                <li>
                    <a href="http://delicious.com/acdha" rel="me">del.icio.us</a>
                </li>
                <li>
                    <a href="http://twitter.com/acdha" rel="me">Twitter</a>
                </li>
                <li>
                    <a href="https://plus.google.com/116562742092842686896?rel=author" rel="me">Google+</a>
                </li>
                <li>
                    <a href="http://www.flickr.com/photos/acdha" rel="me">Flickr</a>
                </li>
                <li>
                    <a href="http://www.linkedin.com/in/acdha" rel="me">LinkedIn</a>
                </li>
                <li>
                    <a href="http://connect.garmin.com/explore?owner=acdha" rel="me">Garmin Connect</a>
                </li>
            </ul>
            <div id="site-search"></div>
        </nav>
        <section id="main">
            <article class="post">
                <header>
                    <meta itemprop="dateCreated" content="2011-02-05T15:46:13-04:00">
                    <meta itemprop="dateModified" content="2011-02-05T15:46:13-04:00"><time class="date" itemprop="datePublished" datetime="2011-02-05T19:46:13+00:00">Feb 05</time>
                    <h2 itemprop="title">
                        Four revolutions
                    </h2>
                </header>
                <div class="body" itemprop="articleBody">
                    <div class="googlereader description" data-google-id="tag:google.com,2005:reader/item/a9d0494c4829fff8">
                        <blockquote>
                            <p>
                                This started out to be a short report on some cool, socially relevant crowdsourcing for Egyptian Arabic. Somehow it morphed into a set of musings about the (near-) future of natural language processingâ€¦
                            </p>
                            <p>
                                A statistical revolution in natural language processing (henceforth NLP) took place in the late 1980s up to the mid 90s or so. Knowledge based methods of the previous several decades were overtaken by data-driven statistical techniques, thanks to increases in computing power, better availability of data, and, perhaps most of all, the (largely DARPA-imposed) re-introduction of the natural language processing community to their colleagues doing speech recognition and machine learning.
                            </p>
                            <p>
                                There was another revolution that took place around the same time, though. When I started out in NLP, the big dream for language technology was centered on human-computer interaction: we'd be able to speak to our machines, in order to ask them questions and tell them what we wanted them to do. (My first job out of college involved a project where the goal was to take natural language queries, turn them into SQL, and pull the answers out of databases.) This idea has retained its appeal for some people, <a href="http://itre.cis.upenn.edu/~myl/languagelog/archives/004812.html">e.g., Bill Gates</a>, but in the mid 1990s something truly changed the landscape, pushing that particular dream into the background: the Web made text important again. If the statistical revolution was about the <em>methods</em>, the Internet revolution was about the <em>needs</em>. All of a sudden there was a world of information out there, and we needed ways to locate relevant Web pages, to summarize, to translate, to ask questions and pinpoint the answers.
                            </p>
                            <p>
                                Fifteen years or so later, the next revolution is already well underway.<br>
                            </p>
                            <p>
                                This really achieved clarity for me in a couple of recent conversations with <a href="http://www.cs.jhu.edu/~ccb/">Chris Callison-Burch</a> and JHU student <a href="http://www.clsp.jhu.edu/people/snovotne/">Scott Novotney</a>. Chris is one of the leaders in the use of crowdsourcing, particularly using <a href="http://en.wikipedia.org/wiki/Amazon_Mechanical_Turk">Amazon Mechanical Turk</a>, to <a href="http://sites.google.com/site/amtworkshop2010/">acquire data language technologists care about</a>. When I heard that Google and its new acquisition, SayNow, were working with Twitter to <a href="http://www.engadget.com/2011/02/01/google-saynow-and-twitter-team-up-to-make-tweeting-from-egypt/">make tweeting from Egypt possible via voicemail</a>, I asked Chris whether he was thinking of perhaps crowdsourcing translations from Arabic to English, much as Rob Munro of Stanford did <a href="http://languagelog.ldc.upenn.edu/nll/?p=2068">for Haitian Creole SMS messages in the wake of the January 2010 earthquake</a>. It turned out that he and Scott Novotney were already on it.
                            </p>
                            <p>
                                The first step is getting from speech to text. Scott reports that they grabbed an initial batch of about 10 hours' worth of voicemails from the first week, and they are doing further collection once per day. They're applying their <a href="http://www.aclweb.org/anthology/N/N10/N10-1024.bib">previous Mechanical Turk based speech transcription framework</a> to Egyptian Arabic, and feeding the resulting text to the folks at <a href="http://egypt.alive.in/">Alive in Egypt</a>, where it will join the results of transcriptions by volunteers. One can expect their natural next step to be <a href="http://www.aclweb.org/anthology/W/W10/W10-0733.bib">crowdsourcing the translations</a> on Mechanical Turk also.
                            </p>
                            <p>
                                What's happening here is very cool, just for its social relevance. Two forms of crowdsourcing (volunteer-based and market-based) are being applied in order to connect the <a href="http://www.huffingtonpost.com/2011/01/30/egypt-revolution-2011_n_816026.html">Egyptian revolution</a> with the rest of the world, via the spoken word. Restoration of Internet access hasn't slowed it down, either: <a href="http://www.washingtonpost.com/wp-dyn/content/article/2011/02/04/AR2011020405374.html">this Washington Post article</a> reports, "Some of the heaviest volume came after access to both Twitter and the Internet was restored in Egypt earlier this week. The alternative method of tweeting has turned into a forum for longer-form expression because the voice recordings aren't confined to Twitter's 140-character limit."
                            </p>
                            <p>
                                But what's happening here is more than socially relevant; it also points to the next revolution in the language technology world. The speech recognition community has been putting plenty of effort into automatic speech recognition (ASR) for Arabic over the last ten years, with a great deal of progress having been made. So why isn't ASR a part of Novotney and Callison-Burch's picture here?
                            </p>
                            <p>
                                It's because the systems that exist are just not ready for the kind of language they're being faced with in this use case. The availability of training data for this scenario is paltry, 20 hours of transcribed telephone speech available for Egyptian Arabic. People have tried applying models trained on the more readily available modern standard Arabic (MSA) to dialects, but the word error rates are atrociously high; Scott comments that for, say, Levantine Arabic, you see word error rates of <em>70 percent</em> or higher. So, apply ASR to Egyptian voice tweets? Don't even bother.
                            </p>
                            <p>
                                We're seeing the same thing everywhere. NLP for social media is the wild west: lots of people are getting into the action (how many different companies are doing sentiment analysis of Twitter right now?), but most of what's out there is really shallow, because the data just don't look like the language the community has been focused on. Apply the usual off-the-shelf analysis tools? For tweets, at least, don't even bother. (Noah Smith noted recently that <a href="http://www.ark.cs.cmu.edu/">he and his team</a> are currently brainstorming on ways to get decent <em>part-of-speech tagging</em> for tweets. Deeper analysis is surely going to take a while.)
                            </p>
                            <p>
                                So, the next revolution of language technology needs is the social media revolution. The trickle that's started showing up as individual papers and at <a href="http://conferences.inf.ed.ac.uk/socialmedia10/">specialized workshops</a>, is, I think, shortly going to become a flood. Beginning around 1990 or so, we saw the rise and eventual ubiquity of statistical papers in NLP (illustrated nicely on slide 58 of <a href="http://www.cs.jhu.edu/~kchurch/wwwfiles/TSD.ppt">this 2004 presentation by Ken Church</a><a>). I suspect that 2010 or hereabouts will eventually be a similar marker, the point where social media datasets started to become unavoidable, and, with them, corresponding need-driven technological approaches ranging from</a> <a href="http://languagelog.ldc.upenn.edu/research.google.com/pubs/archive/35179.pdf">fully unsupervised</a> (when there's enough data) to semi-supervised (bootstrapping from those nice crowdsourced annotations we've been talking about).
                            </p>
                            <p>
                                Here's what had Scott Novotney most jazzed about the Egyptian Arabic crowdsourcing he's doing, when we spoke: the fact that he's now got a "nice little corpus of 10 hours of dialect data" from the real world, which is going to allow him to bootstrap into ASR for real-world Egyptian dialect using semi-supervised techniques. That's the future, right there.<br>
                            </p>
                        </blockquote>
                    </div>
                    <p class="bookmark-source">
                        Source: <a href="http://languagelog.ldc.upenn.edu/nll/?p=2946">http://languagelog.ldc.upenn.edu/nll/?p=2946</a>
                    </p>
                </div>
            </article>
            <nav id="post-nav"></nav><script id="discus-javascript">
    var disqus_shortname = 'improbable';

                (function() {
                    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                    dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
                    document.getElementsByTagName('body')[0].appendChild(dsq);
                })();
            </script><a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
            <div id="disqus_thread"></div>
        </section>
        <footer id="site-footer" class="nocontent">
            <p>
                This site is purely my personal work and does not reflect the views of my employer.
            </p>
            <p class="license">
                <a class="icon" rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/deed.en_US"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-sa/3.0/88x31.png"></a> This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/deed.en_US">Creative Commons Attribution-ShareAlike 3.0 Unported License</a>.
            </p>
        </footer><script async="" defer src="/static/js/common.js">
</script><script id="google-analytics">
    var _gaq = _gaq || [];
            _gaq.push(['_setAccount', 'UA-2097834-1']);
            _gaq.push(['_setDomainName', 'improbable.org']);
            _gaq.push(['_trackPageview']);

            (function() {
                var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
                ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
                var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
            })();
        </script>
    </body>
</html>
