<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>
            TraceVis: performance visualization for TraceMonkey
        </title>
        <meta name="viewport" content="width=device-width,initial-scale=1.0">
        <link rel="stylesheet" href="/static/css/main.min.css" type="text/css" media="all"><!--[if lte IE 8]>
            <link rel="stylesheet" href="/static/css/ie-fixes.css" type="text/css" media="all">
            <script src="/static/js/html5shiv.js"></script>
        <![endif]-->
        <meta http-equiv="last-modified" content="Fri, 27 Feb 2009 02:32:55 GMT">
        <link rel="alternate" type="application/atom+xml" title="All Posts (Atom)" href="/feeds/all.atom">
        <link rel="alternate" type="application/rss+xml" title="All Posts (RSS)" href="/feeds/all.rss">
        <link rel="icon" type="image/jpeg" sizes="287x287" href="/static/img/favicon-287x287.jpg">
        <link rel="icon" type="image/jpeg" sizes="128x128" href="/static/img/favicon-128x128.jpg">
        <script type="application/javascript">
var _prum={id:"5166be01e6e53d1007000001"};var PRUM_EPISODES=PRUM_EPISODES||{};PRUM_EPISODES.q=[];PRUM_EPISODES.mark=function(b,a){PRUM_EPISODES.q.push(["mark",b,a||new Date().getTime()])};PRUM_EPISODES.measure=function(b,a,b){PRUM_EPISODES.q.push(["measure",b,a,b||new Date().getTime()])};PRUM_EPISODES.done=function(a){PRUM_EPISODES.q.push(["done",a])};PRUM_EPISODES.mark("firstbyte");(function(){var b=document.getElementsByTagName("script")[0];var a=document.createElement("script");a.type="text/javascript";a.async=true;a.charset="UTF-8";a.src="//rum-static.pingdom.net/prum.min.js";b.parentNode.insertBefore(a,b)})();
        </script>
    </head>
    <body class="blog post_detail" itemscope itemtype="http://schema.org/BlogPosting">
        <nav id="site-nav">
            <header id="about">
                <h1>
                    <a href="/about/">Chris Adams</a>
                </h1>
                <h2>
                    Programmer, cyclist, photographer
                </h2>
            </header>
            <ul class="links">
                <li>
                    <a href="/">Home</a>
                </li>
                <li>
                    <a href="/about/">About</a>
                </li>
                <li>
                    <a href="/feeds/all.atom" title="Site Feed">Site Feed</a>
                </li>
            </ul>
            <ul class="social-networks">
                <li>
                    <a href="https://github.com/acdha" rel="me">Github</a>
                </li>
                <li>
                    <a href="http://bitbucket.org/acdha" rel="me">Bitbucket</a>
                </li>
                <li>
                    <a href="http://delicious.com/acdha" rel="me">del.icio.us</a>
                </li>
                <li>
                    <a href="http://twitter.com/acdha" rel="me">Twitter</a>
                </li>
                <li>
                    <a href="https://plus.google.com/116562742092842686896?rel=author" rel="me">Google+</a>
                </li>
                <li>
                    <a href="http://www.flickr.com/photos/acdha" rel="me">Flickr</a>
                </li>
                <li>
                    <a href="http://www.linkedin.com/in/acdha" rel="me">LinkedIn</a>
                </li>
                <li>
                    <a href="http://connect.garmin.com/explore?owner=acdha" rel="me">Garmin Connect</a>
                </li>
            </ul>
            <div id="site-search"></div>
        </nav>
        <section id="main">
            <article class="post">
                <header>
                    <meta itemprop="dateCreated" content="2009-02-26T21:32:55-04:00">
                    <meta itemprop="dateModified" content="2009-02-26T21:32:55-04:00"><time class="date" itemprop="datePublished" datetime="2009-02-27T01:32:55+00:00">Feb 27</time>
                    <h2 itemprop="title">
                        TraceVis: performance visualization for TraceMonkey
                    </h2>
                </header>
                <div class="body" itemprop="articleBody">
                    <div class="googlereader description" data-google-id="tag:google.com,2005:reader/item/7a9ae5a55b0c3d9c">
                        <blockquote>
                            <p>
                                I’ve been working on a visualization of TraceMonkey performance, with the goal of revealing what the JS VM is doing, and why it runs certain programs fast or slow, so we can figure out how to make the slow ones fast too. In this post, I want to show off the results and explain how to read them, hopefully explaining a bit about how TraceMonkey works in general while I’m at it.
                            </p>
                            <p>
                                <strong>Background on TraceMonkey.</strong> First, I need to explain how TraceMonkey works at a high level. Readers who already know the basic ideas behind TraceMonkey can skip to the next section.
                            </p>
                            <p>
                                Before TraceMonkey (TM), we had an interpreter. The fundamental idea of TM is to select hot (frequently run) regions of JS code, compile them to fast native code (x86, ARM), and then use the native code for those regions.
                            </p>
                            <p>
                                In all compilers, generating fast native code requires a lot of information about the program’s run-time behavior. Specifically, the compiler needs to know what values are constant in what regions, what branches are or are not always taken, and, crucially for dynamic languages like JS, what types variables have in what regions. For example, in compiling JS <strong>a+b</strong>, if we don’t know the types of <strong>a</strong> and <strong>b</strong>, the compiler needs to generate native code to handle every type combination, along with type tests and branches on the run-time types. And then the compiler has to carry along extra bits to record the type, and previous operations that set <strong>a</strong> and <strong>b</strong> need to generate those extra bits. And so on. That’s a lot of native code, and it’s only slightly more efficient than the interpreter. Conversely, if the compiler knows the types are both, say, <strong>double</strong>, then the compiler can simply generate a native add instruction, which is as fast as possible.
                            </p>
                            <p>
                                It’s hard for the compiler to figure out types and other such information for dynamic languages like JS. One reason it’s hard is the lack of type declarations, but there are others, such as the ability of <strong>eval</strong> to create new variables with values of any type at any time.
                            </p>
                            <p>
                                TraceMonkey solves this problem by collecting information for the compiler dynamically. That is, when TM wants to compile a certain region of code, it actually runs that region in the interpreter. As the interpreter runs, TM records the path taken through the code and all the types and constant values seen. The result is a linear <strong>trace</strong> through the code with type, value, and branch annotations. The compiler (nanojit) can then relatively easily compile the trace to fast native code.
                            </p>
                            <p>
                                Now, for many programs this works wonderfully and the program runs 2-20x faster in TraceMonkey vs. the pure interpreter, but some programs don’t speed up or run more slowly. We need to understand why in order to improve TM.
                            </p>
                            <p>
                                <strong>TraceMonkey VM <em>Activities</em>.</strong> To better understand TM performance, I broke down what TM does into 6 major <em>activities</em>.
                            </p>
                            <ul>
                                <li>When TM starts running a program, it always starts by <strong>interpreting</strong> the program, exactly as in the non-tracing JS engine.
                                </li>
                                <li>When execution reaches a point where TM might want to start a compiled trace, TM spends a bit of time <strong>monitoring</strong> the execution: checking to see if it already has a compiled region, counting the number of times passed, and deciding whether to start a trace. Monitoring is a kind of overhead: while monitoring, TM isn’t running the user’s program, but monitoring is a necessary cost of finding and optimizing traces.
                                </li>
                                <li>If TM does decide to create a new compiled trace, it runs in the interpreter while <strong>recording</strong> the trace, including operations and types of values. During this time, it is running user code a little slower than the basic interpreter.
                                </li>
                                <li>When the trace is finished, TM <strong>compiles</strong> the trace to native code. This is another form of overhead.
                                </li>
                                <li>As I mentioned above, as part of monitoring, TM checks to see if it already has a compiled native trace starting at the current point. If so, TM selects the right trace and prepares to run it, which I call <strong>executing</strong> the trace. This is a third form of overhead.
                                </li>
                                <li>Finally, TM can be running <strong>native</strong> code compiled previously. Compiled native traces run 2-20x faster than the interpreter, with a typical speedup factor of about 2.5.
                                </li>
                            </ul>
                            <p>
                                <strong>Visualizing TraceMonkey Activities.</strong> Now, let’s see how that looks in a picture. I’m going to use 2loops.js, a sample program that computes the mean and variance of the numbers 0-999,999 using two separate loops:
                            </p>
                            <pre style="font-size:14pt;background-color:#eeeeff;margin-bottom:12px;padding:4px;line-height:1.2">
var n = 100000;
var sum = 0;
for (var i = 0; i &lt; n; ++i) {
  sum += i;
}
var sum_squares = 0;
for (var i = 0; i &lt; n; ++i) {
  sum_squares += i * i;
}
var mean = sum / n;
var variance = sum_squares / n - mean * mean;
print('mean:     ' + mean);
print('variance: ' + variance);
</pre>
                            <p>
                                Here is the TraceVis output. Click for a version large enough to actually read. The numbered boxes going clockwise around the chart show how to read each element of the chart and what the chart tells us about what TM is doing.
                            </p>
                            <p>
                                <a href="http://people.mozilla.org/~dmandelin/tracevis/graphs/tracevis.png"><br>
                                <img src="http://people.mozilla.org/~dmandelin/tracevis/graphs/tracevis-t.png" alt="TraceVis output"></a>
                            </p>
                            <p>
                                <strong>TraceVis on SunSpider</strong> <a href="http://people.mozilla.org/~dmandelin/tracevis/web/sunspider.html">Click here</a> for TraceVis output for all the SunSpider benchmarks. I give the speedup vs. pure interpretation on the front page so you can get a feel for what pictures go with slow and fast execution. Here are a few examples interpreted in detail:
                            </p>
                            <p>
                                <strong>crypto-sha1</strong> traces very well, with a 6x speedup vs. the interpreter. The picture looks a lot like the picture for 2loops.js, but with more traces:
                            </p>
                            <p>
                                <a href="http://people.mozilla.org/~dmandelin/tracevis/graphs/crypto-sha1.png"><br>
                                <img src="http://people.mozilla.org/~dmandelin/tracevis/graphs/crypto-sha1-t.png" alt="TraceVis crypto-sha1"></a>
                            </p>
                            <p>
                                The middle purple and blue stripes are interesting: TM had to create 6 native traces before it was able to really switch to native code. Figuring out why this happens requires additional tools. In this case, because there aren't too many traces, debug spew (environment variable TRACEMONKEY=verbose) is readable. To find where all the traces start recording, I took a debug shell build and ran <code>TRACEMONKEY=verbose dist/bin/js -j ../t/crypto-sha1.js | grep starting</code>. I got:
                            </p>
                            <pre>
recording starting from ../t/crypto-sha1.js:221@119
recording starting from ../t/crypto-sha1.js:152@29
recording starting from ../t/crypto-sha1.js:152@39
recording starting from ../t/crypto-sha1.js:63@154
recording starting from ../t/crypto-sha1.js:63@159
recording starting from ../t/crypto-sha1.js:90@5
recording starting from ../t/crypto-sha1.js:91@31
recording starting from ../t/crypto-sha1.js:92@52
recording starting from ../t/crypto-sha1.js:55@111
recording starting from ../t/crypto-sha1.js:177@34
</pre>
                            <p>
                                There are 10 places recording started, corresponding to the 10 purple bands in TraceVis. Numbering from 1, 4-9 are the traces for the middle band. The first two traces are for the loop starting at line 61, which is an inner loop. (Inner loops get hot before outer loops, so they tend to be traced first.) The traces cover two different paths through the if. Then, the tracer ends up discovering 3 different hot paths through the function sha1_ft around line 90, so they are traced as well. Finally, an outer loop at line 53 gets hot, so it gets traced as well. At this point, there are enough traces to cover all the cases, so we get to stay on native code until the containing function returns.
                            </p>
                            <p>
                                Thus, the purple/blue banding pattern followed by a long stretch of green indicates the buildup of several traces through a loop to account for different paths or types or inner and outer loops. Once enough traces have been compiled to cover all the hot code of a loop (or set of nested loops), the chart goes green until the loop is done.
                            </p>
                            <p>
                                If you zoom in, you can actually see short bands of yellow and green in between the wide bands of purple and blue. This is because after compiling one of these traces, TM starts tries to execute the native code. Often TM gets several iterations in right away before it exits and needs to record more traces. Computers being fast and all, "several iterations" is usually a few microseconds or less.
                            </p>
                            <p>
                                <strong>3d-cube</strong> traces moderately well, achieving a 2.5x speedup over the interpreter. Let's see why it doesn't trace as well as sha1:
                            </p>
                            <p>
                                <a href="http://people.mozilla.org/~dmandelin/tracevis/graphs/3d-cube.png"><br>
                                <img src="http://people.mozilla.org/~dmandelin/tracevis/graphs/3d-cube-t.png" alt="TraceVis 3d-cube"></a>
                            </p>
                            <p>
                                Here we have the familiar purple/blue buildup of compiled traces, but once we finish compiling, we don't go solid green. Instead, we get a pattern that looks like blades of grass with red tips on a white background. Zooming in and looking at the vertical dimension, we can see that we get a bit of red (monitoring), then a bit of yellow (preparing to execute), then a strip of green (native code), then a bit of yellow (cleaning up after executing), then a bit of red (finish monitoring), then a strip of white (interpreter), and the pattern repeats.
                            </p>
                            <p>
                                This means we are repeatedly starting to execute native code, but then we are forced to leave the native code for the interpreter within a few microseconds. Evidently, the native code runs pretty fast, because we are getting a good total speedup even though we spend about 1/3 of our time in the base interpreter.
                            </p>
                            <p>
                                The next question is why we are leaving native code and returning to the interpreter, which this visualization doesn't answer. There are about a dozen different reasons why we can exit from native code. I have another prototype instrumentation patch that counts the different exit reasons and and how much time we spend in the interpreter for each reason.
                            </p>
                            <p>
                                For 3d-cube, the vast majority (3808 of 3907) of these exits are for a reason I apparently called <strong>loop2</strong> when I wrote the patch. As you may expect, I didn't know what <strong>loop2</strong> actually meant, but after conferring with Andreas, I learned that loop2 means we exiting an outer loop. When we exit an inner loop, we know we are still inside a loop, so we are probably in some hot code and should continue trying to record traces. But if we exit an outer loop, we are presumably back to one-shot code, which does not benefit from tracing.
                            </p>
                            <p>
                                But we exit this way 3808 times, which is impossible unless we are inside a loop. So something must be wrong. I used debug spew again, this time looking for "leaving trace" messages. Most of them are at lines 57 and 100 of 3d-cube.js. Line 57 is a loop inside a function DrawLine that appears to iterate over the pixels in a line. DrawLine is called only in a function DrawQube. DrawQube is called by Loop, which implements a loop by recursion, which TraceMonkey currently doesn't support.
                            </p>
                            <p>
                                So, we can probably speed up 3d-cube even more by either (a) tracing recursion, (b) tracing tail recursion as loops (Loop is tail recursive), or (c) extending traces from outer loops if the outer loop exit becomes hot. And we didn't actually know this until now.
                            </p>
                            <p>
                                <strong>string-tagcloud</strong> traces badly: it runs 5% slower with the JIT turned on.
                            </p>
                            <p>
                                <a href="http://people.mozilla.org/~dmandelin/tracevis/graphs/string-tagcloud.png"><br>
                                <img src="http://people.mozilla.org/~dmandelin/tracevis/graphs/string-tagcloud-t.png" alt="TraceVis string-tagcloud"></a>
                            </p>
                            <p>
                                The pattern has 3 phases.
                            </p>
                            <p>
                                In phase 1, which accounts for about half of total time, we are running in the pure interpreter. The first real code run by this test is: <code>var tagInfo = tagInfoJSON.parseJSON(...)</code> over 175k of JSON. parseJSON is recursive. TM doesn't even see any loop headers in that part, so TM never even goes to monitoring mode.
                            </p>
                            <p>
                                In phase 2, we have a white background with purple streaks and lots of red dots. The purple streaks are recording traces, but note that there is no blue to represent compilation. So the traces must be aborting for some reason; i.e., they encounter some feature TM doesn't know how to trace. The red dots indicate that TM is seeing loop headers and monitoring them, but not doing anything with them, probably because no traces can be successfully compiled for them.
                            </p>
                            <p>
                                To understand phase 2 in detail, we need to know why recording is failing. Grepping the spew for 'Abort' will get the answer. In this case, all but 1 of the aborts are: <code>Abort recording (line 184, pc 64): callname.</code> This means tracing is stopping on a JSOP_CALLNAME bytecode in the interpreter. Line 184 contains a recursive call to a function <strong>walk</strong> defined inside another function. Poking around a bit, I noticed that a detailed message would be printed with lower-case 'abort', so I tried that and got <code>abort: 4815: fp-&gt;scopeChain is not global or active call object</code>. I found that error message in the code, and after a little debugging I found the reason the abort is activated.
                            </p>
                            <p>
                                The problem is that during lookup of the variable <strong>walk</strong> in the function call expression, <strong>walk</strong> is found in an enclosing scope that is a function call scope that is not part of the trace. Whenever that happens, the tracer aborts. I think this is just an implementation limitation: in order to call the function, the tracer needs to have the function in its "tracker", so that it can refer to the LIR opcode that loads the function. (That's just how it works right now.) But if the function is defined "above" the trace, then the tracer's tracker will not have seen it.
                            </p>
                            <p>
                                I think this wouldn't matter if we supported recursion, because then the outer scope would be part of the trace anyway.
                            </p>
                            <p>
                                Phase 3 consists of a little bit of recording and compiling, followed by a big patch of native code execution. That's the loop inside the function makeTagCloud, which doesn't do anything scary and traces well.
                            </p>
                            <p>
                                <strong>Conclusion.</strong> I've explained how to read TraceVis charts, and then showed how to read the charts along with other debug info to diagnose performance problems (or performance wins) in detail.
                            </p>
                            <p>
                                I want to thank my girlfriend Natalie for inspiring TraceVis by sending me an <a href="http://www.law.com/jsp/legaltechnology/pubArticleLT.jsp?id=1202428248638&amp;rss=newswire">article on visualizations in computer forensics</a>.
                            </p>
                            <p>
                                The code is available in my <a href="http://hg.mozilla.org/users/dmandelin_mozilla.com/tracevis/">personal hg repository</a>. You can check out a local copy by running
                            </p>
                            <pre>
hg clone http://hg.mozilla.org/users/dmandelin_mozilla.com/tracevis/
</pre>
                            <p>
                                The repo includes the patch that instruments TM with activity counters and a bunch of Python scripts for processing the outputs. The image generation scripts require <a href="http://www.pythonware.com/products/pil/">PIL (Python Imaging Library)</a>.
                            </p>
                            <p>
                                Looking at SunSpider charts is fun, but I really want to apply this tool to performance problems in real applications like bugs <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=463487">463487</a>, <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=463478">463478</a>, <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=465773">465773</a>, and <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=468840">468840</a>. I'd also like to look at the V8 benchmarks, where TM currently doesn't do as well as it does on SunSpider.
                            </p>
                        </blockquote>
                    </div>
                    <p class="bookmark-source">
                        Source: <a href="http://blog.mozilla.com/dmandelin/2009/02/26/tracevis-performance-visualization-for-tracemonkey/">http://blog.mozilla.com/dmandelin/2009/02/26/tracevis-performance-visualization-for-tracemonkey/</a>
                    </p>
                </div>
            </article>
            <nav id="post-nav"></nav><script id="discus-javascript">
    var disqus_shortname = 'improbable';

                (function() {
                    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                    dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
                    document.getElementsByTagName('body')[0].appendChild(dsq);
                })();
            </script><a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
            <div id="disqus_thread"></div>
        </section>
        <footer id="site-footer">
            <p>
                This site is purely my personal work and does not reflect the views of my employer.
            </p>
            <p class="license">
                <a class="icon" rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/deed.en_US"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-sa/3.0/88x31.png"></a> This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/deed.en_US">Creative Commons Attribution-ShareAlike 3.0 Unported License</a>.
            </p>
        </footer><script async="" defer src="/static/js/common.js">
</script><script id="google-analytics">
    var _gaq = _gaq || [];
            _gaq.push(['_setAccount', 'UA-2097834-1']);
            _gaq.push(['_setDomainName', 'improbable.org']);
            _gaq.push(['_trackPageview']);

            (function() {
                var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
                ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
                var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
            })();
        </script>
    </body>
</html>
