<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>Feature: Confirmation bias in science: how to avoid it</title>
        <meta name="viewport" content="width=device-width,initial-scale=1.0">
        <link rel="stylesheet" href="/static/css/main.min.css" type="text/css" media="all">
        <!--[if lte IE 8]>
            <link
                rel="stylesheet"
                href="/static/css/ie-fixes.css"
                type="text/css"
                media="all"
            />
            <script src="/static/js/html5shiv.js"></script>
        <![endif]-->

        <meta http-equiv="last-modified" content="Wed, 14 Jul 2010 01:15:00 GMT">
        <link rel="alternate" type="application/atom+xml" title="All Posts (Atom)" href="/feeds/all.atom">
        <link rel="alternate" type="application/rss+xml" title="All Posts (RSS)" href="/feeds/all.rss">
        <link rel="icon" type="image/jpeg" sizes="287x287" href="/static/img/favicon-287x287.jpg">
        <link rel="icon" type="image/jpeg" sizes="128x128" href="/static/img/favicon-128x128.jpg">
    </head>
    <body class="blog post_detail" itemscope itemtype="http://schema.org/BlogPosting">
        <nav id="site-nav">
            <header id="about">
                <h1><a href="/about/">Chris Adams</a></h1>
                <h2>Programmer, cyclist, photographer</h2>
            </header>
            <ul class="links">
                <li>
                    <a href="/">Home</a>
                </li>
                <li>
                    <a href="/about/">About</a>
                </li>
                <li>
                    <a href="/feeds/all.atom" title="Site Feed">Site Feed</a>
                </li>
            </ul>
            <ul class="social-networks">
                <li>
                    <a rel="me" href="https://code4lib.social/@acdha">Mastodon</a>
                </li>
                <li>
                    <a href="https://github.com/acdha" rel="me">Github</a>
                </li>
                <li>
                    <a href="https://bitbucket.org/acdha" rel="me">Bitbucket</a>
                </li>
                <li>
                    <a href="https://pinboard.in/u:acdha/" rel="me">Pinboard</a>
                </li>
                <li>
                    <a href="https://www.flickr.com/photos/acdha" rel="me">Flickr</a>
                </li>
                <li>
                    <a href="https://www.linkedin.com/in/acdha" rel="me">LinkedIn</a>
                </li>
            </ul>
            <div id="site-search"></div>
        </nav>
        <section id="main">
            <article class="post">
                <header>
                    <meta itemprop="dateCreated" content="2010-07-13T21:15:00-04:00">
                    <meta itemprop="dateModified" content="2010-07-13T21:15:00-04:00">
                    <time class="date" itemprop="datePublished" datetime="2010-07-14T01:15:00+00:00">Jul 14</time>
                    <h2 class="" itemprop="title">Feature: Confirmation bias in science: how to avoid it</h2>
                </header>

                <div class="body" itemprop="articleBody"><div class="googlereader description" data-google-id="tag:google.com,2005:reader/item/fa42c37a2fe960ff">
                        <blockquote>
                            <a href="http://arstechnica.com/science/news/2010/07/confirmation-bias-how-to-avoid-it.ars?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss"><img vspace="4" hspace="4" border="0" align="right" width="230" height="129" src="http://static.arstechnica.com/assets/2010/07/test_tube_science_list_ars-thumb-230x130-15344-f.jpg"></a>
                            <p>
                                One of the most common arguments against a scientific finding is confirmation bias: the scientist or scientists only look for data that confirms a desired conclusion. Confirmation bias is remarkably common—it is used by psychics, mediums, mentalists, and homeopaths, just to name a few. As you may guess from such a list, deliberate use of confirmation bias is held in low esteem by scientists, and allowing confirmation bias to get the better of your results is regarded as a particularly sad form of incompetence.
                            </p>
                            <p>
                                Yet, whenever science meets some ideological barrier, scientists are accused of, at best, self-deception, and, at worst, deliberate fraud. Examples of this are scattered across the Internet with respect to evolution, gun control, sex education, and, of course, global warming. Let's take a look at three cases: in two cases, scientists were certainly duped by confirmation bias: the case of N-rays and homeopathy. In the last case—sex in Samoan society—we can see how difficult it can be to either establish or refute confirmation bias. I will then follow that up with a story from my own research, which shows how everyday scientific practice is designed to avoid falling into the trap of confirmation bias.
                            </p>
                            <h3>
                                The amazing case of N-Rays
                            </h3>To understand how N-rays came about, we need to go back to the late 18th century and consider the cultural milieu of the time. The major European nations had their chests puffed out with pride: they were great and they knew it. Each was so great that they were convinced that they were greater than any of the others. National pride itself was even something to take pride in and polish up on Sundays like some classic car.
                            <p>
                                Scientists were a part of this, and national pride provided a significant motivation for their work. The UK was very happy with the likes of Faraday, Maxwell, and others, while the Germans had Hertz, Plank, and Roentgen, who had just discovered X-rays. The French may have felt a little left out in all of this, because, although they were making major contributions, they hadn't made as big of a splash as, for instance Roentgen and his X-rays.
                            </p>
                            <p>
                                That is, they hadn't until Prosper-René Blondlot announced the discovery of N-rays. He was immediately famous in France, and very shortly afterwards, researchers from around the world confirmed that they too had seen N-rays. N-rays were an ephemeral thing: observed only as a corona around an electric discharge from certain crystals. They were only observed by the human eye, making them difficult to quantify.
                            </p>
                            <p>
                                But not everyone was convinced. Many researchers outside of France were suspicious of the number of claims coming from French labs for the properties of N-rays. In the end, an American scientist Robert Wood visited the lab of Blondlot to see it for himself. During one of the experiments he surreptitiously removed the crystal that supposedly generated the N-rays, after which Blondlot failed to notice the absence of N-rays. The N-rays failed to vanish when their source was removed.
                            </p>
                            <p>
                                You might think that the story ends there, but it doesn't. National pride was such that some French researchers continued to publish research on N-rays in French journals for a number of years. If we look back, we can see how the N-ray fiasco developed—the French <em>needed</em> something stranger and more useful than X-rays. But we can also see why it collapsed—the experiments were readily repeatable, and there was a large, diverse, and active scientific community ready to put their oars in. In the end, only a small fraction of physicists studying in the area of radiation were taken in, and only for a short time.
                            </p>
                            <h3>
                                Water memories
                            </h3>One of the most prominent examples of confirmation bias involved another French researcher, named <a href="http://arstechnica.com/science/news/2007/09/the-pseudoscience-behind-homeopathy.ars/1">Jacques Benveniste</a>. He spent a great deal of time and effort studying the effect of histamines. Naturally, a histamine causes an anti-histamine reaction in certain tests. However, what Benveniste reported in <em>Nature</em> was that the reaction got stronger as the histamine solution was diluted—even when it was highly improbable that there was any histamine left in the solution. Water, in effect, had a memory of the histamine.
                            <p>
                                His research was published in spite of the fact that the reviewers expressed disbelief in the results, because they couldn't see an obvious flaw in the methods. Normally, the results would have been left to stand until independent researchers had either corroborated the finding or found the methodological flaw. In this case, however, <em>Nature</em> felt that the results had to be corroborated as quickly as possible. To achieve this, they sent a group of observers to examine the experiment in more detail.
                            </p>
                            <p>
                                They found that the positive result was due to inadequate blinding. The anti-histamine reaction had to be assessed by examining a reaction—in other words, there was a strong element of human judgement involved. And the researchers performing the analysis knew which samples should give a positive result. When the experiment was performed with complete blinding, the positive result disappeared.
                            </p>
                            <p>
                                The consequence of this was that the researchers involved in the Benveniste's work effectively withdrew from the scientific community. To this day, they still perform follow-up research on that original null result, making increasingly fantastical claims about homeopathic remedies. They, along with other homeopathic researchers, form a community apart. The community, as far as I can tell, has very little internal debate over findings, being neither critical nor receiving criticism.
                            </p>
                            <p>
                                The key point in these two stories is that confirmation bias was found rather quickly, and those scientists who refused to acknowledge it were quickly isolated from their peers. When controversial results turn up in good science, the result is rather different.
                            </p>
                            <h3>
                                Free lovin' Samoans?
                            </h3>Our next example is of a woman named Margaret Mead who was an anthropologist. In the early 20th century, she landed in Samoa and interviewed a number of teenage girls on their view of sex and relationships. Being teenage girls, they, with her encouragement, may have spun her one hell of a line: Samoans appeared to be the ultimate free loving society. Girls started early, and got their kicks with anyone they pleased. Nothing was hidden, so there was no difficult transition through the adolescence years. Then, when the fun was over, the girls settled down to monogamous marriages.
                            <p>
                                Her book, first published in 1928, shocked and appalled conservative westerners. But it may have generated outrage in Samoa if the Samoans had known.
                            </p>
                            <p>
                                Modern Samoans are highly religious with strictly prescribed roles for boys, girls, men, and women. These roles certainly do not involve <em>open</em> casual sex—though statistics have shown that, just like all other societies, there is a fair percentage of adolescent promiscuity behind the scenes. In fact, when mixed with Western culture, the results were a bit dysfunctional, with some Samoan boys, in particular, coping poorly with a more openly promiscuous society. 
                            </p>
                            <p>
                                This led to suspicion of Mead's results, and a New Zealand researcher named Derek Freeman returned to Samoa and re-interviewed some of the now elderly women that Mead had originally interviewed. In 1985, he published his own account detailing how Mead had got it wrong.
                            </p>
                            <p>
                                His accusation is essentially one of confirmation bias, but, unlike the previous case, here he is accusing an entire field of confirmation bias. Understandably, they have not taken this lying down, and they have a point. Certainly, in modern Samoan society, Christianity is universal and virginity is important. But, when Mead lived in Samoa, Samoans were not Christian. Had their conversion influenced their stories? Most certainly. Had their culture changed? Yes.
                            </p>
                            <p>
                                So, did either Mead or Freeman fall under the spell of confirmation bias? Certainly, Freeman set out with the explicit goal of trying to figure out why the Samoan community in New Zealand was so at odds with that described in Mead's book. Mead, on the other hand, set out to see if Western cultural mores played any role in adolescent difficulties. I think it's safe to say that both had a preferred conclusion. But did that prevent them from reporting their findings accurately?
                            </p>
                            <p>
                                I must admit I find it hard to believe that Mead could spend nine months in Samoa, observing life and rituals and interviewing women and still get it so completely wrong. But, it is also difficult to reconcile modern Samoa with Mead's findings.
                            </p>
                            <p>
                                All of this goes to show how hard it can be. Her very presence, and her newness to Samoan culture, made her a prime target for being fed a line. Furthermore, field trips cost money, and her work came just before the great depression, which was followed by the second World War. By the time anyone would do more work, the Islands had gone through a major cultural shift. 
                            </p>
                            <p>
                                The point is that the observations cannot be repeated. But this does not mean that the scientific community is unaware of the issue, and both sides of the debate have brought new evidence to the table, and offered observations that seem to refute each other's conclusions. All of which tells us that, even if Mead or Freeman fell victim to confirmation bias, the whole field is certainly healthy and still debating their findings.
                            </p>
                            <h3>
                                The practice of avoiding confirmation bias
                            </h3>
                            <p>
                                One of my areas of research interest is the development of new microscope imaging techniques. In particular, we want to do an end-run around the laws of physics to be able to see features in cells and other objects that would otherwise be physically impossible to see. Now, our approach to the problem was not to run into the lab and try a bunch of different ideas. Instead, we built a model of the physical process of light emission for the particular class of microscope imaging we were interested in, and then we began to play. In the end, we found not one, but two different ways to attain our goal. One is described <a href="http://arstechnica.com/science/news/2009/12/beating-the-diffraction-limit-using-cars-microscopy.ars">here</a>, and the other paper is available <a href="http://arxiv.org/abs/0911.2332">here</a>.
                            </p>
                            <p>
                                That short paragraph describes about two years of work. But the total amount of time coding the model? Maybe 24 hours, total. OK, call it 36 hours with some debugging. Running the code to get results? Maybe a minute per parameter set, so let's call it a month. 
                            </p>
                            <p>
                                So that's 32 days from around 730 total. What was all the rest of that time devoted to? Trying to anticipate every possible objection to our approach. Checking if those objections were valid. Trying to find examples of physically realistic parameters to test our model with. Seeing if the code was actually modeling what we thought it was. Making sure that our assumptions were valid. In summary, we were trying to prove ourselves wrong.
                            </p>
                            <p>
                                This is always the first step in the scientific process. I have an idea, I discuss it with my colleagues, and we try to destroy it. The better the idea sounds, the harder we try. Scientists are very wary of the "too good to be true" syndrome. Moving on from that, when data turns up, we try to destroy that too. Is that noise? Is the numerical routine unstable? Are we seeing the accumulation of rounding errors? Maybe the signal is not signal?
                            </p>
                            <p>
                                In the end, we couldn't destroy our idea or the results, and the work got sent off to be published. This is the first time that a complete stranger gets to see the work, but it's only a few people, and they may not be all that interested in our particular bit of work. So this is a rather low hurdle that we've jumped.
                            </p>
                            <h3>
                                Risk and its rewards
                            </h3>
                            <p>
                                Now, we could just stop there and concentrate solely on doing the experiment suggested by our modeling results. But, just a few weeks ago, I was at a conference presenting these results to our peers. We don't get much in the way of bonus points for doing this: the university barely recognizes conferences as scientific output. And trumpeting your results to the world gives everyone else a chance to beat you—an experimental demonstration beats a theory paper any day of the week. Still, I was there. Why?
                            </p>
                            <p>
                                The answer is simple. Our science becomes stronger as more scientists interact with it. Before, we had faced a few objections from a total of four to six people (the referees for the papers). Now, I was facing a room full of experts who had, before the meeting, expressed <em>great interest</em> in our results. If there was a hole in the model, this would be the occasion for me to fall into it. Was there a hole?
                            </p>
                            <p>
                                The question session was fast and lively. And, yes, after the session, a senior scientist approached me and told me in no uncertain terms why our idea would not work—that sound you heard was me falling down the hole in our model. He was, and still is, right. 
                            </p>
                            <p>
                                What was my reaction to that? First, I had to understand his objection. Then, I had to consider if it was a fundamental problem. In short, I discussed it with him and my colleagues. I did not—as creationists, homeopaths, or global warming skeptics do—ignore the objection and continue onwards. Nor did I react as if I had been personally attacked—despite having put my heart and soul into this work, and really, really wanting it to succeed.
                            </p>
                            <p>
                                Thankfully, the story doesn't end there. Although he was right, it turns out that we can beat his objection as well. However, it certainly changes how we plan to do the experiment. Some of the choices that we had thought were relatively free are rather restricted. If we had not exposed our ideas to more criticism, we would never have known, and it is likely that our planned experiments would never have succeeded.
                            </p>
                            <p>
                                The key point is that everyone at the conference wants us to succeed. They want us to find a way to make this particular improvement. But they are also skeptical that we can make their microscopes see smaller objects. Their skepticism is what helps us get to our goal faster. And this is true of every field of science. Every criticism hurts like hell, but after the bruises have healed, we find that our results are more accurate.
                            </p>
                            <h3>
                                Science as a contact sport
                            </h3>
                            <p>
                                This is the difference between doing science from the inside and observing it from the outside. We attack each other's ideas mercilessly, and those attacks are not ignored. Sometimes, it turns out that the objection was the result of a misunderstanding, and once the misunderstanding is cleared up, the objection goes away. Objections that are relevant result in ideas being discarded or modified. And the key to this is that the existence of confirmation bias is both acknowledged and actively fought against.
                            </p>
                            <p>
                                You will note that in the two clear cases of confirmation bias, once it was confirmed, scientists stopped pursuing the claim. Those that continued to try and publish were quickly isolated. In the third case, we see how hard it can be to detect confirmation bias. Nevertheless, the debate surrounding the work remains robust, and new evidence is presented as it becomes available. Critically, neither side of the debate is actively suppressed.
                            </p>
                            <p>
                                This is why I have been using the term "denier." If you carefully examine the debate in the climate science community, you will find that objections <em>are</em> considered carefully and seriously—even the ones that originate from the likes of McIntyre and McKitrick. However, once a problem is addressed to the point where another problem is bigger, scientists move on. 
                            </p>
                            <p>
                                Deniers, however, do not move on. Even if the objection is shown to be completely spurious—for instance, creationists often falsely claim that evolution is in conflict with the second law of thermodynamics—deniers do not give them up. In effect, this means that anything you say and do to help them understand your work is ignored completely. This is why some figures in the climate debate end up the denier camp and outside the science camp.
                            </p>
                            <p>
                                <a href="http://arstechnica.com/science/news/2010/07/confirmation-bias-how-to-avoid-it.ars?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss&amp;comments=1#comments-bar">Read the comments on this post</a>
                            </p>
                        </blockquote>
                    </div>
                    <p class="bookmark-source">
                        Source: <a href="http://arstechnica.com/science/news/2010/07/confirmation-bias-how-to-avoid-it.ars?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss">http://arstechnica.com/science/news/2010/07/confirmation-bias-how-to-avoid-it.ars?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</a>
                    </p>
                </div>
            </article>

            <nav id="post-nav">


            </nav>
        </section>

        <footer id="site-footer" class="nocontent">
            <p>
                This site is purely my personal work and does not reflect the
                views of my employer.
            </p>
            <p class="license">
                <a class="icon" rel="license" href="https://creativecommons.org/licenses/by-sa/3.0/deed.en_US"><img alt="Creative Commons License" style="border-width: 0" src="https://i.creativecommons.org/l/by-sa/3.0/88x31.png"></a>
                This work is licensed under a
                <a rel="license" href="https://creativecommons.org/licenses/by-sa/3.0/deed.en_US">Creative Commons Attribution-ShareAlike 3.0 Unported
                    License</a>.
            </p>
        </footer>

        <script async src="/static/js/common.js"></script>
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/prettify/r298/run_prettify.min.js" integrity="sha256-hj+5FRlAuvAFANiefn0PpJYCkV1X4QT9EgiPd+6QnCw=" crossorigin="anonymous"></script>
    </body>
</html>
